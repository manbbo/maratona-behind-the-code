metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# MARATONA BEHIND THE CODE 2020\n\n## DESAFIO 6 - LIT"}, {"metadata": {}, "cell_type": "markdown", "source": "<hr>"}, {"metadata": {}, "cell_type": "markdown", "source": "## Installing Libs"}, {"metadata": {}, "cell_type": "code", "source": "!pip install scikit-learn --upgrade", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "Requirement already up-to-date: scikit-learn in /opt/conda/envs/Python36/lib/python3.6/site-packages (0.23.2)\r\nRequirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn) (1.2.0)\r\nRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn) (1.15.4)\r\nRequirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn) (2.1.0)\r\nRequirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn) (0.16.0)\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install xgboost --upgrade", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "Requirement already up-to-date: xgboost in /opt/conda/envs/Python36/lib/python3.6/site-packages (1.2.0)\r\nRequirement already satisfied, skipping upgrade: numpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from xgboost) (1.15.4)\r\nRequirement already satisfied, skipping upgrade: scipy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from xgboost) (1.2.0)\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install imblearn --upgrade", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "Requirement already up-to-date: imblearn in /opt/conda/envs/Python36/lib/python3.6/site-packages (0.0)\r\nRequirement already satisfied, skipping upgrade: imbalanced-learn in /opt/conda/envs/Python36/lib/python3.6/site-packages (from imblearn) (0.7.0)\r\nRequirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.2.0)\r\nRequirement already satisfied, skipping upgrade: scikit-learn>=0.23 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (0.23.2)\r\nRequirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (0.16.0)\r\nRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.15.4)\r\nRequirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn>=0.23->imbalanced-learn->imblearn) (2.1.0)\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<hr>"}, {"metadata": {}, "cell_type": "markdown", "source": "## Download dos conjuntos de dados em formato .csv"}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/vanderlei-test/dataset-3/master/training_dataset.csv\ndf_training_dataset = pd.read_csv(r'training_dataset.csv')\ndf_training_dataset.tail()", "execution_count": null, "outputs": [{"output_type": "stream", "text": "--2020-09-04 17:11:34--  https://raw.githubusercontent.com/vanderlei-test/dataset-3/master/training_dataset.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.112.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.112.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1736600 (1.7M) [text/plain]\nSaving to: \u2018training_dataset.csv.9\u2019\n\n100%[======================================>] 1,736,600   --.-K/s   in 0.07s   \n\n2020-09-04 17:11:35 (22.5 MB/s) - \u2018training_dataset.csv.9\u2019 saved [1736600/1736600]\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Sobre o arquivo \"training_dataset.csv\", temos algumas informa\u00e7\u00f5es gerais sobre os usu\u00e1rios da plataforma:\n\n**id**\n\n**graduacao**\n\n**universidade**\n\n**profissao**\n\n**organizacao**\n\n**pretende_fazer_cursos_lit**\n\n**interesse_mba_lit**\n\n**importante_ter_certificado**\n\n**horas_semanais_estudo**\n\n**como_conheceu_lit**\n\n**total_modulos**\n\n**modulos_iniciados**\n\n**modulos_finalizados**\n\n**certificados**\n\n**categoria**"}, {"metadata": {}, "cell_type": "markdown", "source": "<hr>\n\n## Detalhamento do desafio: classifica\u00e7\u00e3o multiclasse\n\nEste \u00e9 um desafio cujo objetivo de neg\u00f3cio \u00e9 a segmenta\u00e7\u00e3o dos usu\u00e1rios de uma plataforma de ensino. Para tal, podemos utilizar duas abordagens: aprendizado de m\u00e1quina supervisionado (classifica\u00e7\u00e3o) ou n\u00e3o-supervisionado (clustering). Neste desafio ser\u00e1 aplicada a classifica\u00e7\u00e3o, pois \u00e9 dispon\u00edvel um dataset j\u00e1 com \"labels\", ou em outras palavras, j\u00e1 com exemplos de dados juntamente com a vari\u00e1vel alvo.\n\nNa biblioteca scikit-learn temos diversos algoritmos para classifica\u00e7\u00e3o. O participante \u00e9 livre para utilizar o framework que desejar para completar esse desafio.\n\nNeste notebook ser\u00e1 mostrado um exeplo de uso do algoritmo \"Decision Tree\" para classificar parte dos estudantes em seis diferentes perf\u00eds."}, {"metadata": {}, "cell_type": "markdown", "source": "# Aten\u00e7\u00e3o!\n\nA coluna-alvo neste desafio \u00e9 a coluna ``categoria``"}, {"metadata": {}, "cell_type": "markdown", "source": "<hr>"}, {"metadata": {}, "cell_type": "code", "source": "#IMPORTS\n\nfrom sklearn.impute import SimpleImputer\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# MUDAR"}, {"metadata": {}, "cell_type": "code", "source": "id_var_name = 'id'\ntarget_name = 'categoria'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def is_imbalanced(df, target_name, tolerance):\n    \"\"\"\n    \n\n    Parameters\n    ----------\n    df : pandas.Dataframe\n        df.\n    target_name : string\n        target_name.\n    tolerance : int\n        Tolerance percentage.\n\n    Returns\n    -------\n    boolean\n        True if is imbalanced, else False.\n\n    \"\"\"\n    # Print the unique Churn values\n    print(set(df[target_name]))\n    # Calculate the ratio size of each churn group\n    ratio_size = df.groupby([target_name]).size() / df.shape[0] * 100\n    ratio_size_min = ratio_size[ratio_size.idxmin()]\n    print(ratio_size)\n    print(ratio_size_min)\n    return (ratio_size_min <= tolerance)\n\n\nimbalanced = is_imbalanced(df_training_dataset, target_name = target_name, tolerance = 30)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def split_cat_num_vars(df, id_var_name, target_name, prepare_for_ml=True, get_num=True, bf_proc_cols = []):\n    if bf_proc_cols:\n        df_bf_proc = df[bf_proc_cols]\n        dict_rename_cols = {}\n        for col in bf_proc_cols:\n            dict_rename_cols[col] = col + \"_bf_proc\"\n        df_bf_proc = df_bf_proc.rename(columns=dict_rename_cols)\n\n    custid = [id_var_name]\n    target = [target_name]\n    categorical = df.nunique()[df.nunique() < 10].keys().to_list()\n    if target[0] in categorical:\n        categorical.remove(target[0])\n\n    numerical = [col for col in df.columns\n                 if col not in categorical + custid + target]\n    \n    if not prepare_for_ml:\n        if get_num:\n            return df[numerical]\n        else:\n            return df[categorical]\n    else:\n    \n        ## One-hot encode categorical features\n        # drop_first : we remove the first encoded column, as it is redundant and can be infered from the others\n        df = pd.get_dummies(data = df, columns = categorical, drop_first = True)\n            \n        ## Scale the numerical features\n        # Some ML models requires this step, because otherwise variables with larger mean and standard deviation would\n        # have more influence as predictors\n        \n        scaler = StandardScaler()\n        \n        # Note: TotalCharges type = Object\n        # You can use the to_numeric method in order to convert the values under the Price column into a float:\n        # By setting errors=\u2019coerce\u2019, you\u2019ll transform the non-numeric values into NaN.\n        \n        for col in df[numerical].loc[:,df[numerical].dtypes == 'object']:\n            df[col] = pd.to_numeric(df[col], errors='coerce')\n            \n        scaled_numerical = scaler.fit_transform(df[numerical])\n        # Remove Nan and infinite values\n        scaled_numerical = np.nan_to_num(scaled_numerical)\n        \n        # Build a DataFrame from scaled_numerical\n        scaled_numerical = pd.DataFrame(scaled_numerical, columns=numerical)\n        # scaled_numerical.fillna(scaled_numerical.mean())\n        \n        ## Bringing all together:\n        \n        # Drop non-scaled numerical columns\n        df = df.drop(columns=numerical, axis=1)\n        \n        # Merge the non-numerical with the scaled numerical data\n        df_final = df.merge(right = scaled_numerical,\n                                how = 'left',\n                                left_index=True,\n                                right_index = True)\n        if bf_proc_cols:\n            df_final = df_final.merge(right = df_bf_proc,\n                                    how = 'left',\n                                    left_index=True,\n                                    right_index = True)\n\n    return(df_final)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "si = SimpleImputer(\n    missing_values=np.nan,  # os valores faltantes s\u00e3o do tipo ``np.nan`` (padr\u00e3o Pandas)\n    strategy='most_frequent'\n)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\ntrain_df_prepared = split_cat_num_vars(df_training_dataset, id_var_name, target_name, prepare_for_ml=True, get_num=True, bf_proc_cols = [])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.model_selection import train_test_split\n\n#### Split the data\ndef split_train_test(df, target_name, id_var_name, test_size):\n\n    # Split X and Y into training and testing datasets\n    train, test = train_test_split(df, test_size = test_size, random_state = 332)\n    \n    # Store column names from `telcom` excluding target variable and customer ID\n    cols = [col for col in df.columns if col not in id_var_name + target_name]\n    \n    # Extract training features\n    train_X = train[cols]\n    \n    # Extract training target\n    train_Y = train[target_name]\n    \n    # Extract testing features\n    test_X = test[cols]\n    \n    # Extract testing target\n    test_Y = test[target_name]\n    return(train_X, train_Y, test_X, test_Y)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\ntrain_X, train_Y, test_X, test_Y = split_train_test(train_df_prepared, target_name=target_name, id_var_name=id_var_name, test_size=0.2)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "sm = SMOTE(random_state = 3)\ntrain_X_res, train_Y_res = sm.fit_resample(train_X, train_Y)\n\ntrain_Y_res.value_counts()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def grid_search_pipeline_class(X_train, X_test, y_train, y_test, pipeline_steps, grid_parameters):\n    \"\"\"\n    \n\n    Parameters\n    ----------\n    Ex:\n    pipeline_steps = [('imputation', Imputer(missing_values='NaN', strategy='most_frequent', axis=0)),\n            ('scaler', StandardScaler()),\n             ('SVM', SVC())]\n    grid_parameters = {'SVM__C':[1, 10, 100],\n                  'SVM__gamma':[0.1, 0.01]}\n\n    Returns\n    -------\n    cv : TYPE\n        DESCRIPTION.    \n\n    \"\"\"\n    \n    pipeline = Pipeline(pipeline_steps)\n    \n    # Create train and test sets\n    # X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=21)\n    \n    # Instantiate the GridSearchCV object: cv\n    cv = GridSearchCV(estimator = pipeline, param_grid = grid_parameters, cv=3)\n    \n    # Fit to the training set\n    cv.fit(X_train,y_train)\n    \n    # Predict the labels of the test set: y_pred\n    y_pred = cv.predict(X_test)\n    \n    # Compute and print metrics\n    print(\"Accuracy: {}\".format(cv.score(X_test, y_test)))\n    print(classification_report(y_test, y_pred))\n    print(\"Tuned Model Parameters: {}\".format(cv.best_params_))\n    \n    return cv, y_pred", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.ensemble import RandomForestClassifier\n\npipeline = Pipeline(steps=[\n    ('imputer', si),\n    ('Rfc', OneVsRestClassifier(XGBClassifier(n_jobs=-2, max_depth = 4, learning_rate = 0.15, gamma=0.20,  min_child_weight = 6, random_state=42, colsample_bytree=0.7)))\n    #('Rdf', RandomForestClassifier(random_state=0))\n])\n\n\npipeline.fit(train_X_res, train_Y_res.values.ravel())\n\ny_pred = pipeline.predict(test_X)\n# Compute metrics\nprint(classification_report(test_Y, y_pred))\nprint(accuracy_score(test_Y, y_pred))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Analisando a qualidade do modelo atrav\u00e9s da matriz de confus\u00e3o"}, {"metadata": {}, "cell_type": "code", "source": "import matplotlib.pyplot as plt\nimport numpy as np\nimport itertools\n\n\ndef plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.metrics import confusion_matrix\n\n\nplot_confusion_matrix(confusion_matrix(test_Y, y_pred), ['perfil1', 'perfil2', 'perfil3', 'perfil4', 'perfil5', 'perfil6'])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<hr>"}, {"metadata": {}, "cell_type": "markdown", "source": "## Scoring dos dados necess\u00e1rios para entregar a solu\u00e7\u00e3o"}, {"metadata": {}, "cell_type": "markdown", "source": "Como entrega da sua solu\u00e7\u00e3o, esperamos os resultados classificados no seguinte dataset chamado \"to_be_scored.csv\":"}, {"metadata": {}, "cell_type": "markdown", "source": "### Download da \"folha de respostas\""}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/vanderlei-test/dataset-3/master/to_be_scored.csv\ndf_to_be_scored = pd.read_csv(r'to_be_scored.csv')\ndf_to_be_scored.tail()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<hr>\n\n# Aten\u00e7\u00e3o!\n\n# Para poder aplicar seu modelo e classificar a folha de respostas, voc\u00ea precisa primeiro aplicar as mesmas transforma\u00e7\u00f5es com colunas que voc\u00ea aplicou no dataset de treino.\n\n# N\u00e3o remova ou adicione linhas na folha de respostas. \n\n# N\u00e3o altere a ordem das linhas na folha de respostas.\n\n# Ao final, as 1000 entradas devem estar classificadas, com os valores previstos em uma coluna chamada \"target\"\n\n<hr>"}, {"metadata": {}, "cell_type": "markdown", "source": "Na c\u00e9lula abaixo, repetimos rapidamente os mesmos passos de pr\u00e9-processamento usados no exemplo dado com \u00e1rvore de decis\u00e3o"}, {"metadata": {}, "cell_type": "code", "source": "#df_to_be_scored_dummies = pd.get_dummies(df_to_be_scored, columns=['profissao'])\n\ndf_to_be_scored_prepared = split_cat_num_vars(df_to_be_scored, id_var_name, target_name, prepare_for_ml=True, get_num=True, bf_proc_cols = [])\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<hr>\n\nPode ser verificado abaixo que as colunas da folha de resposta agora s\u00e3o id\u00eanticas \u00e0s que foram usadas para treinar o modelo:"}, {"metadata": {}, "cell_type": "markdown", "source": "# Aten\u00e7\u00e3o\n\nPara todas colunas que n\u00e3o existirem no \"df_to_be_scored\", voc\u00ea pode usar a t\u00e9cnica abaixo para adicion\u00e1-las:"}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "y_pred = pipeline.predict(df_to_be_scored_prepared.loc[:, df_to_be_scored_prepared.columns != id_var_name])\ndf_to_be_scored[\"target\"] = y_pred", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Salvando a folha de respostas como um arquivo .csv para ser submetido"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "project.save_data(file_name=\"results.csv\", data=df_to_be_scored.to_csv(index=False))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Aten\u00e7\u00e3o\n\n# A execu\u00e7\u00e3o da c\u00e9lula acima ir\u00e1 criar um novo \"data asset\" no seu projeto no Watson Studio. Voc\u00ea precisar\u00e1 realizar o download deste arquivo juntamente com este notebook e criar um arquivo zip com os arquivos **results.csv** e **notebook.ipynb** para submiss\u00e3o. (os arquivos devem estar nomeados desta forma)"}, {"metadata": {}, "cell_type": "markdown", "source": "<hr>\n\n## Parab\u00e9ns!\n\nSe voc\u00ea j\u00e1 est\u00e1 satisfeito com a sua solu\u00e7\u00e3o, v\u00e1 at\u00e9 a p\u00e1gina abaixo e envie os arquivos necess\u00e1rios para submiss\u00e3o.\n\n# https://lit.maratona.dev\n"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}
