{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# MARATONA BEHIND THE CODE 2020\n\n## DESAFIO 2: PARTE 2"}, {"metadata": {}, "cell_type": "markdown", "source": "### Introdu\u00e7\u00e3o"}, {"metadata": {}, "cell_type": "markdown", "source": "Na parte 1 deste desafio, voc\u00ea realizou o pr\u00e9-processamento e o treinamento de um modelo a partir de um conjunto de dados base fornecido. Nesta segunda etapa voc\u00ea ir\u00e1 integrar todas as transforma\u00e7\u00f5es e eventos de treinamento criados anteriormente em uma Pipeline completa para *deploy* no **Watson Machine Learning**!"}, {"metadata": {}, "cell_type": "markdown", "source": "### Prepara\u00e7\u00e3o do Notebook"}, {"metadata": {}, "cell_type": "markdown", "source": "Primeiro realizaremos a instala\u00e7\u00e3o do scikit-learn e a importa\u00e7\u00e3o das mesmas bibliotecas utilizadas anteriormente"}, {"metadata": {}, "cell_type": "code", "source": "!pip install scikit-learn==0.20.0 --upgrade", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import json\nimport requests\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import KFold, cross_validate", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "\u00c9 necess\u00e1rio inserir o conjunto de dados base novamente como um dataframe pandas, seguindo as instru\u00e7\u00f5es\n\n![alt text](https://i.imgur.com/K1DwL9I.png \"importing-csv-as-df\")\n\nAp\u00f3s a sele\u00e7\u00e3o da op\u00e7\u00e3o **\"Insert to code\"**, a c\u00e9lula abaixo ser\u00e1 preenchida com o c\u00f3digo necess\u00e1rio para importa\u00e7\u00e3o e leitura dos dados no arquivo .csv como um DataFrame Pandas."}, {"metadata": {}, "cell_type": "code", "source": "\nimport types\nimport pandas as pd\n\n## Removed the \"body\" variable, so you could adapt\n\ndf_data_1 = pd.read_csv(body)\ndf_data_1.head()\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Constru\u00e7\u00e3o da Pipeline completa para encapsulamento no WML"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Preparando transforma\u00e7\u00f5es personalizadas para carregamento no WML"}, {"metadata": {}, "cell_type": "markdown", "source": "Na etapa anterior, foi mostrado como criar uma transforma\u00e7\u00e3o personalizada, atrav\u00e9s da declara\u00e7\u00e3o de uma classe Python com os m\u00e9todos ``fit`` e ``transform``.\n\n    - C\u00f3digo da transforma\u00e7\u00e3o personalizada DropColumns():\n    \n    from sklearn.base import BaseEstimator, TransformerMixin\n    # All sklearn Transforms must have the `transform` and `fit` methods\n    class DropColumns(BaseEstimator, TransformerMixin):\n        def __init__(self, columns):\n            self.columns = columns\n        def fit(self, X, y=None):\n            return self\n        def transform(self, X):\n            # Primeiro realizamos a c\u00f3pia do dataframe 'X' de entrada\n            data = X.copy()\n            # Retornamos um novo dataframe sem as colunas indesejadas\n            return data.drop(labels=self.columns, axis='columns')\n\nPara integrar esses tipos de transforma\u00e7\u00f5es personalizadas nas Pipelines do Watson Machine Learning, \u00e9 necess\u00e1rio primeiramente empacotar seu c\u00f3digo personalizado como uma biblioteca Python. Isso pode ser feito facilmente com o uso da ferramenta *setuptools*.\n\nNo seguinte reposit\u00f3rio git: https://github.com/vnderlev/sklearn_transforms temos todos os arquivos necess\u00e1rios para a cria\u00e7\u00e3o de um pacote Python, nomeado **my_custom_sklearn_transforms**.\nEsse pacote possui a seguinte estrutura de arquivos:\n\n    /my_custom_sklearn_transforms.egg-info\n        dependency_links.txt\n        not-zip-safe\n        PKG-INFO\n        SOURCES.txt\n        top_level.txt\n    /my_custom_sklearn_transforms\n        __init__.py\n        sklearn_transformers.py\n    PKG-INFO\n    README.md\n    setup.cfg\n    setup.py\n    \nO arquivo principal, que ir\u00e1 conter o c\u00f3digo das nossas transformadas personalizadas, \u00e9 o arquivo **/my_custom_sklearn_transforms/sklearn_transformers.py**. Se voc\u00ea acess\u00e1-lo no reposit\u00f3rio, ir\u00e1 notar que ele cont\u00e9m exatamente o mesmo c\u00f3digo declarado na primeira etapa (a classe DropColumns).\n\nCaso voc\u00ea tenha declarado transforma\u00e7\u00f5es pr\u00f3prias (al\u00e9m da DropColumn fornecida), voc\u00ea dever\u00e1 adicionar todas as classes dessas transformadas criadas por voc\u00ea nesse mesmo arquivo. Para tal, voc\u00ea deve realizar o fork desse reposit\u00f3rio (isso pode ser feito na pr\u00f3pria interface Web do Github, clicando no bot\u00e3o conforme a imagem abaixo), e adicionar suas classes personalizadas no arquivo **sklearn_transformers.py**.\n\n![alt text](https://i.imgur.com/D81E1uM.png \"forking-a-repo\")\n\nSe voc\u00ea somente fez o uso da transforma\u00e7\u00e3o fornecida (DropColumns), pode ignorar essa etapa de fork, e seguir utilizando o pacote base fornecido! :)\n\nAp\u00f3s a prepara\u00e7\u00e3o do seu pacote Python com as suas transformadas personalizadas, substitua o link do reposit\u00f3rio git na c\u00e9lula abaixo e execute-a. Caso voc\u00ea n\u00e3o tenha preparado nenhuma nova transformada, execute a c\u00e9lula com o link do reposit\u00f3rio j\u00e1 fornecido. \n\n<hr>\n    \n**OBSERVA\u00c7\u00c3O**\n\nCaso a execu\u00e7\u00e3o da c\u00e9lula abaixo retorne um erro de que o reposit\u00f3rio j\u00e1 existe, execute:\n\n**!rm -r -f sklearn_transforms**"}, {"metadata": {}, "cell_type": "code", "source": "# substitua o link abaixo pelo link do seu reposit\u00f3rio git (se for o caso)\n!git clone https://github.com/vnderlev/sklearn_transforms.git", "execution_count": 28, "outputs": [{"output_type": "stream", "text": "fatal: destination path 'sklearn_transforms' already exists and is not an empty directory.\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!cd sklearn_transforms\n!ls -ltr", "execution_count": 29, "outputs": [{"output_type": "stream", "text": "total 68\r\ndrwxr-x--- 5 dsxuser dsxuser  4096 Sep  1 00:22 sklearn_transforms\r\n-rw-r----- 1 dsxuser dsxuser 62139 Sep  1 00:22 sklearn_transforms.zip\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Para subir o c\u00f3digo no WML, precisamos enviar um arquivo .zip com todo o c\u00f3digo fonte, ent\u00e3o iremos zipar o diret\u00f3rio clonado em seguida:"}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "!zip -r sklearn_transforms.zip sklearn_transforms", "execution_count": 30, "outputs": [{"output_type": "stream", "text": "updating: sklearn_transforms/ (stored 0%)\r\nupdating: sklearn_transforms/setup.py (deflated 46%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms.egg-info/ (stored 0%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms.egg-info/SOURCES.txt (deflated 48%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms.egg-info/PKG-INFO (deflated 33%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms.egg-info/top_level.txt (stored 0%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms.egg-info/not-zip-safe (stored 0%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms.egg-info/dependency_links.txt (stored 0%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms/ (stored 0%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms/__init__.py (stored 0%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms/sklearn_transformers.py (deflated 46%)\r\nupdating: sklearn_transforms/PKG-INFO (deflated 31%)\r\nupdating: sklearn_transforms/README.md (deflated 15%)\r\nupdating: sklearn_transforms/setup.cfg (deflated 16%)\r\nupdating: sklearn_transforms/.git/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/c0/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/c0/e12da6a090fe6b2740d0cbfa7119915a00a643 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/29/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/29/c65b6319ccd5b1c7da36655bb0c44e09fff991 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/29/ffc1c2af8fa4b0ef5eef0ba4fdc441915d1a91 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/c4/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/c4/b90bb9bfb2674c96e6d8aa6cc3c8e58194f953 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/1e/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/1e/1e45038dfc30ed50e6d081ec85e8a3fdfb8913 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/52/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/52/6fb1c4f5a0d3a2482041c7bd3f15263837acf5 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/af/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/af/1140cfcb4e33bc03d9b067c1f7d70147d043d7 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/82/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/82/e0b0b52c39cd1840e7853e6d00986fae5683f4 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/da/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/da/64b79708ea475e8c6b484d837676ce91d9801e (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/24/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/24/7b371c9092731e07412dc5286126ed3a18756a (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/2c/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/2c/de64a17098cba673b28c995910b268f5e34e7a (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/2c/c7a6bf2941a9d553a199a4fe658f0074a54b51 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/f2/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/f2/598626ccd27c586d5b759e5186abc64c058912 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/ee/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/ee/96aaec3459bae7b27b49e17f867db49c3257a8 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/2f/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/2f/ab3357d7d157a7a6bbda08aad6cf19970d2cc3 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/0e/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/0e/cc61a0a4baff0885426f45a8fcb9fbb78f8009 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/a0/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/a0/3066ce73d15efd1cc6449dea7e2b678089edd6 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/d7/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/d7/cfed1a9cf21930beb933ecafb2e3d4d3a77874 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/2e/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/2e/2e5168d3c37ccbaeb3b899da3f30fb6bc70031 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/26/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/26/3abe321ee224139817e2325d5c91ac8f0eed50 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/61/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/61/e62b4f1623878ae0d92ffa812570be417feb82 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/05/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/05/6cab60f81eb62f20ffd3cab59b6d232f0188e9 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/80/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/80/b20e55b5f52a87b7769e08df221e07d9cc0f3a (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/f9/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/f9/842759dbd395649399f47479175e044b6b40ae (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/info/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/b6/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/b6/979f3149443c66198e505c1e761f2766b4ea35 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/7e/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/7e/ae3d08dc940e367e3c1e2ac7a35a8b00df2e12 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/1c/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/1c/49d4656922fe1182c905339ec7a468e6881d99 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/d3/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/d3/697484c118054fc68a13eaac93c2f93536b77e (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/22/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/22/2e658014f5f2a43e16ce3c5e896e00fef1f3d5 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/04/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/04/b1ff2d79c9b11a1d494b6f6d42acb629236af4 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/e8/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/e8/8e9a7c9bc5a570d097ba4001ea0c327cba6f0a (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/5a/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/5a/b47e5cada9bcefbd66782d50edf2a86005dcb5 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/c6/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/c6/4e501fc43c00861aa7ccae744058ba87c304fd (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/54/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/54/a860e717a464beb16bcb21419ab86f8351fbf0 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/54/5d0fb908f733cd9eed69b0004a2dfeb33b5c48 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/06/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/06/998ae152d5b5fad89c81a6853dbbc0830fd6c7 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/9b/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/9b/9fe6ce4d68c31dfc1eb7e923e5c90b0595b24d (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/1b/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/1b/9e7f9e69d0cac5283f551433cdaf8e65199698 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/cb/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/cb/d827fdd178a26f42d8b01c58320b03f3eae7fa (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/c3/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/c3/9f70251de841c8e55e9c58d2fa7dbbe2d2fb0f (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/cc/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/cc/fdab500390127d0490aaf9ee369565b05c41b4 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/e6/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/e6/9de29bb2d1d6434b8b29ae775ad8c2e48c5391 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/8b/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/8b/137891791fe96927ad78e64b0aad7bded08bdc (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/aa/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/aa/1db9544c86800c5018cb8f28d1e74fbd192991 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/bc/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/bc/a817006f92d9e390374c1ed6467fad5ff7bab0 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/bc/bd8f17177cd1afe8396315d2039283fa993390 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/d0/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/d0/4d8adf3dbf886c5799f7f367168b0785f0a4f5 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/39/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/39/d4d3fd1cc23783dbadb2d673f3758863106854 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/39/ccfbaf81e116c9eb9781c7cd0b7acdd5ad10aa (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/pack/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/85/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/85/bd34a4ae5f5c965a082a26b38a3268a662ae2b (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/7b/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/7b/04014fbd820cb0146dcec7965f01f304436510 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/6a/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/6a/3c980900b1ce8383ed0fd1cbcb9195d582cf4e (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/77/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/77/7798a7cedea3a2fddef8dd0b7691c9b1f9f97b (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/8c/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/8c/46dcca21d6dd2c23afb4a858d2b77d56bbf050 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/8c/d09104c54f140d61a6e9fa6c2142d4565ee302 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/21/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/21/64a6e4b4ca3afc26c4b21982d433c8c54039a1 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/99/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/99/bde3a281e0a208866b47dcde00a4e4cd8afca0 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/58/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/58/25ba31fa0c00d63a9dc9865e0c848442a6fbcd (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/46/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/46/862abd9b50e51c99a1f65be820af360594f8c2 (stored 0%)\r\nupdating: sklearn_transforms/.git/HEAD (stored 0%)\r\nupdating: sklearn_transforms/.git/branches/ (stored 0%)\r\nupdating: sklearn_transforms/.git/description (deflated 14%)\r\nupdating: sklearn_transforms/.git/hooks/ (stored 0%)\r\nupdating: sklearn_transforms/.git/hooks/pre-push.sample (deflated 50%)\r\nupdating: sklearn_transforms/.git/hooks/pre-applypatch.sample (deflated 36%)\r\nupdating: sklearn_transforms/.git/hooks/pre-rebase.sample (deflated 59%)\r\nupdating: sklearn_transforms/.git/hooks/commit-msg.sample (deflated 44%)\r\nupdating: sklearn_transforms/.git/hooks/prepare-commit-msg.sample (deflated 46%)\r\nupdating: sklearn_transforms/.git/hooks/update.sample (deflated 68%)\r\nupdating: sklearn_transforms/.git/hooks/pre-commit.sample (deflated 46%)\r\nupdating: sklearn_transforms/.git/hooks/applypatch-msg.sample (deflated 41%)\r\nupdating: sklearn_transforms/.git/hooks/post-update.sample (deflated 27%)\r\nupdating: sklearn_transforms/.git/logs/ (stored 0%)\r\nupdating: sklearn_transforms/.git/logs/HEAD (deflated 29%)\r\nupdating: sklearn_transforms/.git/logs/refs/ (stored 0%)\r\nupdating: sklearn_transforms/.git/logs/refs/heads/ (stored 0%)\r\nupdating: sklearn_transforms/.git/logs/refs/heads/master (deflated 29%)\r\nupdating: sklearn_transforms/.git/logs/refs/remotes/ (stored 0%)\r\nupdating: sklearn_transforms/.git/logs/refs/remotes/origin/ (stored 0%)\r\nupdating: sklearn_transforms/.git/logs/refs/remotes/origin/HEAD (deflated 29%)\r\nupdating: sklearn_transforms/.git/info/ (stored 0%)\r\nupdating: sklearn_transforms/.git/info/exclude (deflated 28%)\r\nupdating: sklearn_transforms/.git/index (deflated 53%)\r\nupdating: sklearn_transforms/.git/refs/ (stored 0%)\r\nupdating: sklearn_transforms/.git/refs/heads/ (stored 0%)\r\nupdating: sklearn_transforms/.git/refs/heads/master (stored 0%)\r\nupdating: sklearn_transforms/.git/refs/remotes/ (stored 0%)\r\nupdating: sklearn_transforms/.git/refs/remotes/origin/ (stored 0%)\r\nupdating: sklearn_transforms/.git/refs/remotes/origin/HEAD (stored 0%)\r\nupdating: sklearn_transforms/.git/refs/tags/ (stored 0%)\r\nupdating: sklearn_transforms/.git/config (deflated 34%)\r\nupdating: sklearn_transforms/.git/packed-refs (deflated 9%)\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Com o arquivo zip do nosso pacote carregado no Kernel deste notebook, podemos utilizar a ferramenta pip para instal\u00e1-lo, conforme a c\u00e9lula abaixo:"}, {"metadata": {}, "cell_type": "code", "source": "!pip install sklearn_transforms.zip", "execution_count": 31, "outputs": [{"output_type": "stream", "text": "Processing ./sklearn_transforms.zip\nBuilding wheels for collected packages: my-custom-sklearn-transforms\n  Building wheel for my-custom-sklearn-transforms (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.tmp/pip-ephem-wheel-cache-l7ui49ij/wheels/8f/88/32/f886e7510a37b111e2a1b7e689e04450acda46732970a7ed78\nSuccessfully built my-custom-sklearn-transforms\nInstalling collected packages: my-custom-sklearn-transforms\n  Found existing installation: my-custom-sklearn-transforms 1.0\n    Uninstalling my-custom-sklearn-transforms-1.0:\n      Successfully uninstalled my-custom-sklearn-transforms-1.0\nSuccessfully installed my-custom-sklearn-transforms-1.0\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Podemos agora realizar a importa\u00e7\u00e3o do nosso pacote personalizado em nosso notabook!\n\nIremos importar a transforma\u00e7\u00e3o DropColumns. Se voc\u00ea possui outras transforma\u00e7\u00f5es personalizadas, n\u00e3o se esque\u00e7a de import\u00e1-las!"}, {"metadata": {}, "cell_type": "code", "source": "from my_custom_sklearn_transforms.sklearn_transformers import DropColumns\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom xgboost import XGBClassifier", "execution_count": 32, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Declarando a Pipeline\n\nAp\u00f3s a importa\u00e7\u00e3o das transforma\u00e7\u00f5es personalizadas como um pacote Python, podemos partir para a declara\u00e7\u00e3o da nossa Pipeline.\n\nO processo \u00e9 bem semelhante ao realizado na primeira etapa, por\u00e9m com algumas diferen\u00e7as importantes, ent\u00e3o preste bem aten\u00e7\u00e3o!\n\nA Pipeline exemplo possui tr\u00eas est\u00e1gios: \n\n    - remover a coluna \"NOME\"\n    - imputar \"zeros\" em todos os valores faltantes\n    - inserir os dados pr\u00e9-processados como entrada em um modelo treinado\n    \nRelembrando, a entrada desta Pipeline ser\u00e1 o conjunto cru de dados fornecido exceto a coluna \"LABELS\" (vari\u00e1vel-alvo a ser determinada pelo modelo).\n\nTeremos ent\u00e3o 17 valores de entrada **na PIPELINE** (no modelo ser\u00e3o 16 entradas, pois a coluna NAME ser\u00e1 removida no primeiro est\u00e1gio ap\u00f3s a transforma\u00e7\u00e3o DropColumn).\n\n    MATRICULA       - n\u00famero de quatro algarismos \u00fanico para cada estudante\n    NOME            - nome completo do estudante\n    FALTAS_DE       - n\u00famero de faltas na disciplina de ``Direito Empresarial``\n    FALTAS_EM       - n\u00famero de faltas na disciplina de ``Empreendedorismo``\n    FALTAS_MF       - n\u00famero de faltas na disciplina de ``Matem\u00e1tica Financeira``\n    MEDIA_DE        - m\u00e9dia simples das notas do aluno na disciplina de ``Direito Empresarial`` (0-10)\n    MEDIA_EM        - m\u00e9dia simples das notas do aluno na disciplina de ``Empreendedorismo`` (0-10)\n    MEDIA_MF        - m\u00e9dia simples das notas do aluno na disciplina de ``Matem\u00e1tica Financeira`` (0-10)\n    HRS_ESTUDO_DE   - horas de estudo particular na disciplina de ``Direito Empresarial``\n    HRS_ESTUDO_EM   - horas de estudo particular na disciplina de ``Empreendedorismo``\n    HRS_ESTUDO_MF   - horas de estudo particular na disciplina de ``Matem\u00e1tica Financeira``\n    REPROVACOES_DE  - n\u00famero de reprova\u00e7\u00f5es na disciplina de ``Direito Empresarial``\n    REPROVACOES_EM  - n\u00famero de reprova\u00e7\u00f5es na disciplina de ``Empreendedorismo``\n    REPROVACOES_MF  - n\u00famero de reprova\u00e7\u00f5es na disciplina de ``Matem\u00e1tica Financeira``\n    LIVROS_TEXTO    - quantidade de livros e textos acessados pelo aluno no sistema da universidade\n    AULAS_AO_VIVO   - horas de aulas ao vivo presenciadas pelo aluno (total em todas as disciplinas)\n    EXERCICIOS      - n\u00famero de exerc\u00edcios realizados pelo estudante (total em todas as disciplinas) no sistema da universidade\n\nA sa\u00edda da Pipeline ser\u00e1 um valor estimado para a coluna \"LABELS\"."}, {"metadata": {}, "cell_type": "code", "source": "# Cria\u00e7\u00e3o de uma Transform personalizada ``DropColumns``\n\nrm_columns = DropColumns(\n    columns=[\"MATRICULA\",\"NOME\"]\n)", "execution_count": 33, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Cria\u00e7\u00e3o de um objeto ``SimpleImputer``\n\nsi = SimpleImputer(\n    missing_values=np.nan,  # os valores faltantes s\u00e3o do tipo ``np.nan`` (padr\u00e3o Pandas)\n    strategy='most_frequent',  # a estrat\u00e9gia escolhida \u00e9 a altera\u00e7\u00e3o do valor faltante por uma constante\n)", "execution_count": 34, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Balanceamento\n\n# Colocando as notas maiores que 10 como 10 para balancear\ndf_data_1.loc[df_data_1[\"NOTA_MF\"] > 10, \"NOTA_MF\"] = 10\ndf_data_1.loc[df_data_1[\"NOTA_GO\"] > 10, \"NOTA_GO\"] = 10\ndf_data_1.loc[df_data_1[\"NOTA_EM\"] > 10, \"NOTA_EM\"] = 10\ndf_data_1.loc[df_data_1[\"NOTA_DE\"] > 10, \"NOTA_DE\"] = 10", "execution_count": 35, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_data_1.head()", "execution_count": 36, "outputs": [{"output_type": "execute_result", "execution_count": 36, "data": {"text/plain": "   MATRICULA                       NOME  REPROVACOES_DE  REPROVACOES_EM  \\\n0     502375          M\u00e1rcia Illiglener               0               0   \n1     397093   Jason Jytereoman Izoimum               0               0   \n2     915288  Bartolomeu In\u00e1cio da Gama               0               0   \n3     192652            Fernanda Guedes               1               3   \n4     949491     Alessandre Borba Gomes               1               3   \n\n   REPROVACOES_MF  REPROVACOES_GO  NOTA_DE  NOTA_EM  NOTA_MF  NOTA_GO  INGLES  \\\n0               0               0      6.2      5.8      4.6      5.9     0.0   \n1               0               0      6.0      6.2      5.2      4.5     1.0   \n2               0               0      7.3      6.7      7.1      7.2     0.0   \n3               1               1      0.0      0.0      0.0      0.0     1.0   \n4               1               1      0.0      0.0      0.0      0.0     1.0   \n\n   H_AULA_PRES  TAREFAS_ONLINE  FALTAS       PERFIL  \n0            2               4       3       EXATAS  \n1            2               4       3       EXATAS  \n2            5               0       3      HUMANAS  \n3            4               4       4  DIFICULDADE  \n4            5               2       5  DIFICULDADE  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MATRICULA</th>\n      <th>NOME</th>\n      <th>REPROVACOES_DE</th>\n      <th>REPROVACOES_EM</th>\n      <th>REPROVACOES_MF</th>\n      <th>REPROVACOES_GO</th>\n      <th>NOTA_DE</th>\n      <th>NOTA_EM</th>\n      <th>NOTA_MF</th>\n      <th>NOTA_GO</th>\n      <th>INGLES</th>\n      <th>H_AULA_PRES</th>\n      <th>TAREFAS_ONLINE</th>\n      <th>FALTAS</th>\n      <th>PERFIL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>502375</td>\n      <td>M\u00e1rcia Illiglener</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6.2</td>\n      <td>5.8</td>\n      <td>4.6</td>\n      <td>5.9</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>EXATAS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>397093</td>\n      <td>Jason Jytereoman Izoimum</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6.0</td>\n      <td>6.2</td>\n      <td>5.2</td>\n      <td>4.5</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>EXATAS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>915288</td>\n      <td>Bartolomeu In\u00e1cio da Gama</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.3</td>\n      <td>6.7</td>\n      <td>7.1</td>\n      <td>7.2</td>\n      <td>0.0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>HUMANAS</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>192652</td>\n      <td>Fernanda Guedes</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>DIFICULDADE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>949491</td>\n      <td>Alessandre Borba Gomes</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>5</td>\n      <td>DIFICULDADE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Defini\u00e7\u00e3o das colunas que ser\u00e3o features (nota-se que a coluna MATRICULA e NOME n\u00e3o est\u00e1 presente)\nfeatures = [\n    'REPROVACOES_DE', 'REPROVACOES_EM', \"REPROVACOES_MF\", \"REPROVACOES_GO\",\n    \"NOTA_DE\", \"NOTA_EM\", \"NOTA_MF\", \"NOTA_GO\",\n    \"INGLES\", \"H_AULA_PRES\", \"NOME\", \"MATRICULA\", \"TAREFAS_ONLINE\", \"FALTAS\", \n]\n\n# Defini\u00e7\u00e3o da vari\u00e1vel-alvo\ntarget = [\"PERFIL\"]\n\n# Prepara\u00e7\u00e3o dos argumentos para os m\u00e9todos da biblioteca ``scikit-learn``\nX = df_data_1[features]\ny = df_data_1[target]", "execution_count": 57, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "**ATEN\u00c7\u00c3O!!**\n\nA c\u00e9lula acima, embora muito parecida com a defini\u00e7\u00e3o de features na primeira etapa deste desafio, possui uma grande diferen\u00e7a!\n\nNela est\u00e1 presente a coluna \"NOME\" como uma feature! Isso ocorre pois neste caso essas s\u00e3o as entradas da *PIPELINE*, e n\u00e3o do modelo."}, {"metadata": {}, "cell_type": "code", "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=337, shuffle=False)", "execution_count": 58, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Na c\u00e9lula abaixo \u00e9 realizada a declara\u00e7\u00e3o de um objeto **Pipeline** do scikit-learn, onde \u00e9 declarado o par\u00e2metro *steps*, que nada mais \u00e9 do que uma lista com as etapas da nossa pipeline:\n\n    'remove_cols'     - transforma\u00e7\u00e3o personalizada DropColumns\n    'imputer'         - transforma\u00e7\u00e3o embutida do scikit-learn para imputa\u00e7\u00e3o de valores faltantes\n    'dtc'             - um classificador via \u00e1rvore de decis\u00e3o\n    \nNote que passamos como passos as transformadas instanciadas anteriormente, sob nome `rm_columns` e `si`."}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import confusion_matrix\n\n# Cria\u00e7\u00e3o da nossa pipeline para armazenamento no Watson Machine Learning:\nmy_pipeline = Pipeline(\n    steps=[\n        ('remove_cols', rm_columns),\n        ('imputer', si),\n        ('rfc', OneVsRestClassifier(XGBClassifier(max_depth=4)))\n    ]\n)", "execution_count": 59, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Em seguida iremos executar o m\u00e9todo `fit()` da Pipeline, realizando o pr\u00e9-processamento e o treinamento do modelo de uma s\u00f3 vez."}, {"metadata": {}, "cell_type": "code", "source": "# Inicializa\u00e7\u00e3o da Pipeline (pr\u00e9-processamento e realiza\u00e7\u00e3o do treinamento do modelo)\nmy_pipeline.fit(X_train, y_train.values.ravel())", "execution_count": 60, "outputs": [{"output_type": "execute_result", "execution_count": 60, "data": {"text/plain": "Pipeline(memory=None,\n     steps=[('remove_cols', DropColumns(columns=['MATRICULA', 'NOME'])), ('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n       strategy='most_frequent', verbose=0)), ('rfc', OneVsRestClassifier(estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n     ..._lambda=1, scale_pos_weight=1, seed=None,\n       silent=True, subsample=1),\n          n_jobs=None))])"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Agora que temos uma pipeline completa, com etapas de pr\u00e9-processamento configuradas e tamb\u00e9m um modelo por \u00e1rvore de decis\u00e3o j\u00e1 treinado, podemos realizar a integra\u00e7\u00e3o com o Watson Machine Learning!"}, {"metadata": {}, "cell_type": "markdown", "source": "### Encapsulando uma Pipeline personalizada no Watson Machine Learning"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Estabelecendo conex\u00e3o entre o cliente Python do WML e a sua inst\u00e2ncia do servi\u00e7o na nuvem"}, {"metadata": {}, "cell_type": "code", "source": "# Biblioteca Python com implementa\u00e7\u00e3o de um cliente HTTP para a API do WML\nfrom watson_machine_learning_client import WatsonMachineLearningAPIClient", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "2020-09-01 01:07:01,669 - watson_machine_learning_client.wml_client_error - WARNING - Artifact with artifact_uid: 'f7822e96-79ec-4f17-9f88-f1593e41e728' does not exist.\n2020-09-01 01:08:23,397 - watson_machine_learning_client.wml_client_error - WARNING - Artifact with artifact_uid: '42db1688-82e0-467e-bad0-53f38dc54929' does not exist.\n2020-09-01 01:08:39,038 - watson_machine_learning_client.wml_client_error - WARNING - Failure during getting all runtimes. (GET https://eu-de.ml.cloud.ibm.com/v4/runtimes?limit=1000)\nStatus code: 404, body: {\"trace\":\"8b620b22a1fcdec1cd81dc59ff978367\",\"errors\":[{\"code\":\"not_found\",\"message\":\"Requested object ce545f51-3707-453c-bacb-049fae1bee8f could not be found.\"}]}\n2020-09-01 01:08:39,044 - watson_machine_learning_client.repository - ERROR - Failure during getting all runtimes. (GET https://eu-de.ml.cloud.ibm.com/v4/runtimes?limit=1000)\nStatus code: 404, body: {\"trace\":\"8b620b22a1fcdec1cd81dc59ff978367\",\"errors\":[{\"code\":\"not_found\",\"message\":\"Requested object ce545f51-3707-453c-bacb-049fae1bee8f could not be found.\"}]}\n2020-09-01 01:08:56,267 - watson_machine_learning_client.wml_client_error - WARNING - Failure during getting runtime specs details. (GET https://eu-de.ml.cloud.ibm.com/v4/runtimes)\nStatus code: 404, body: {\"trace\":\"62beef8cce4a07554cb2a3e0dfc8400f\",\"errors\":[{\"code\":\"not_found\",\"message\":\"Requested object ce545f51-3707-453c-bacb-049fae1bee8f could not be found.\"}]}\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "markdown", "source": "As pr\u00f3ximas c\u00e9lulas ir\u00e3o realizar o deploy da pipeline declarada neste notebook no WML. S\u00f3 prossiga se voc\u00ea j\u00e1 est\u00e1 satisfeito com seu modelo e acha que j\u00e1 \u00e9 a hora de fazer o deploy da sua solu\u00e7\u00e3o.\n\nCole as credenciais de sua inst\u00e2ncia do Watson Machine Learning na vari\u00e1vel na c\u00e9lula abaixo.\n\n\u00c9 importante que a vari\u00e1vel que cont\u00e9m os valores tenha o nome de ``wml_credentials`` para que as pr\u00f3ximas c\u00e9lulas deste notebook executem corretamente."}, {"metadata": {}, "cell_type": "code", "source": "wml_credentials = {\n  \"<you can just copy the wml credentials, but wml doesn't work like that anymore>\"\n}", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Instanciando um objeto cliente do Watson Machine Learning a partir das credenciais fornecidas\n\nclientWML = WatsonMachineLearningAPIClient(wml_credentials)", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "**ATEN\u00c7\u00c3O!!**\n\nFique atento para os limites de consumo de sua inst\u00e2ncia do Watson Machine Learning!\n\nCaso voc\u00ea expire a camada gr\u00e1tis, n\u00e3o ser\u00e1 poss\u00edvel avaliar seu modelo (pois \u00e9 necess\u00e1ria a realiza\u00e7\u00e3o de algumas chamadas de API que consomem predi\u00e7\u00f5es!)"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Listando todos os artefatos armazenados no seu WML"}, {"metadata": {}, "cell_type": "markdown", "source": "Para listar todos os artefatos armazenados em seu Watson Machine Learning, voc\u00ea pode usar a seguinte fun\u00e7\u00e3o:\n\n    clientWML.repository.list()"}, {"metadata": {}, "cell_type": "code", "source": "result = clientWML.deployments.score(\n    model_endpoint_url,\n    scoring_payload\n)\n\nprint(\"\\n Resultados:\")\nprint(json.dumps(result, indent=4))", "execution_count": 75, "outputs": [{"output_type": "stream", "text": "\n Resultados:\n{\n    \"fields\": [\n        \"prediction\",\n        \"probability\"\n    ],\n    \"values\": [\n        [\n            \"DIFICULDADE\",\n            [\n                0.9986030459403992,\n                0.0010330029763281345,\n                6.002801819704473e-05,\n                8.979632548289374e-05,\n                0.00021394914074335247\n            ]\n        ]\n    ]\n}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<hr>\n\n## Parab\u00e9ns! \n\nSe tudo foi executado sem erros, voc\u00ea j\u00e1 tem um classificador baseado em machine learning encapsulado como uma API REST!\n\nPara testar a sua solu\u00e7\u00e3o integrada com um assistente virtual e realizar a submiss\u00e3o, acesse a p\u00e1gina:\n\nhttps://uninassau.maratona.dev\n\nVoc\u00ea ir\u00e1 precisar da endpoint url do seu modelo e das credenciais do WML :)"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}